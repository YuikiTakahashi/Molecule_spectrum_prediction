{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b4a450a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 2.9.1+cpu is available\n",
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sympy as sy\n",
    "\n",
    "# Try importing torch, but don't fail if it's not available\n",
    "try:\n",
    "    import torch\n",
    "    TORCH_AVAILABLE = True\n",
    "    print(f\"PyTorch {torch.__version__} is available\")\n",
    "except ImportError:\n",
    "    TORCH_AVAILABLE = False\n",
    "    print(\"Warning: PyTorch is not installed. Using numpy/scipy for diagonalization.\")\n",
    "    torch = None\n",
    "\n",
    "import ujson as uj\n",
    "\n",
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "from sympy.physics.wigner import wigner_3j, wigner_6j\n",
    "from numpy import linalg as LA\n",
    "from IPython.display import Latex, display\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.collections import LineCollection\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.optimize import least_squares\n",
    "from scipy.stats import norm\n",
    "\n",
    "import Energy_Levels as EL\n",
    "from Energy_Levels import MoleculeLevels\n",
    "from Energy_Levels import (\n",
    "    branching_ratios,\n",
    "    Calculate_TDMs,\n",
    "    Calculate_TDM_evecs,\n",
    "    Calculate_forbidden_TDM_evecs,\n",
    "    Calculate_forbidden_TDMs,\n",
    ")\n",
    "\n",
    "print(\"All imports successful!\")\n",
    "\n",
    "# sns.set()\n",
    "# sns.set_palette('bright')\n",
    "# np.set_printoptions(precision=9, suppress=True)\n",
    "# from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cadc8a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch device: cpu\n",
      "Diagonalization functions configured successfully.\n",
      "Default method: torch\n"
     ]
    }
   ],
   "source": [
    "# Torch device configuration and GPU-ready diagonalization hooks\n",
    "# Only configure torch if it's available\n",
    "if TORCH_AVAILABLE:\n",
    "    try:\n",
    "        TORCH_DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"Using torch device: {TORCH_DEVICE}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not configure torch device: {e}\")\n",
    "        TORCH_AVAILABLE = False\n",
    "else:\n",
    "    TORCH_DEVICE = None\n",
    "    print(\"Torch not available, using numpy/scipy for diagonalization\")\n",
    "\n",
    "# Store original functions\n",
    "if not hasattr(EL, \"diagonalize_cpu\"):\n",
    "    EL.diagonalize_cpu = EL.diagonalize\n",
    "    EL.diagonalize_batch_cpu = EL.diagonalize_batch\n",
    "\n",
    "# Patch the diagonalize function in the Energy_Levels module\n",
    "# This ensures internal calls to diagonalize() use our patched version\n",
    "def diagonalize_with_device(matrix, method=\"torch\", order=False, Normalize=False, round=10):\n",
    "    \"\"\"GPU/CPU-aware diagonalization with proper tensor handling.\"\"\"\n",
    "    if method == \"torch\" and TORCH_AVAILABLE:\n",
    "        try:\n",
    "            tensor = torch.from_numpy(matrix).to(TORCH_DEVICE)\n",
    "            w, v = torch.linalg.eigh(tensor)\n",
    "            # Use detach() to ensure we can convert to numpy even if requires_grad=True\n",
    "            evals = np.round(w.detach().cpu().numpy(), round)\n",
    "            evecs = np.round(v.detach().cpu().numpy().T, round)\n",
    "            if order:\n",
    "                idx_order = np.argsort(evals)\n",
    "                evecs = evecs[idx_order, :]\n",
    "                evals = evals[idx_order]\n",
    "            return evals, evecs\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Torch diagonalization failed: {e}\")\n",
    "            print(\"Falling back to numpy...\")\n",
    "            method = \"numpy\"\n",
    "    # Fallback to original function for non-torch methods\n",
    "    return EL.diagonalize_cpu(matrix, method=method, order=order, Normalize=Normalize, round=round)\n",
    "\n",
    "\n",
    "def diagonalize_batch_with_device(matrix_array, method=\"torch\", round=10):\n",
    "    \"\"\"GPU/CPU-aware batch diagonalization with proper tensor handling.\"\"\"\n",
    "    if method == \"torch\" and TORCH_AVAILABLE:\n",
    "        try:\n",
    "            tensors = torch.from_numpy(matrix_array).to(TORCH_DEVICE)\n",
    "            w, v = torch.linalg.eigh(tensors)\n",
    "            evals = np.round(w.detach().cpu().numpy(), round)\n",
    "            evecs = np.round(v.detach().cpu().numpy().transpose(0, 2, 1), round)\n",
    "            return evals, evecs\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Torch batch diagonalization failed: {e}\")\n",
    "            print(\"Falling back to numpy...\")\n",
    "            method = \"numpy\"\n",
    "    # Fallback to original function for non-torch methods\n",
    "    return EL.diagonalize_batch_cpu(matrix_array, method=method, round=round)\n",
    "\n",
    "\n",
    "# Patch the functions in the module namespace\n",
    "# This replaces the function references so internal calls use the patched version\n",
    "EL.diagonalize = diagonalize_with_device\n",
    "EL.diagonalize_batch = diagonalize_batch_with_device\n",
    "if TORCH_AVAILABLE:\n",
    "    EL.TORCH_DEVICE = TORCH_DEVICE\n",
    "\n",
    "print(\"Diagonalization functions configured successfully.\")\n",
    "print(f\"Default method: {'torch' if TORCH_AVAILABLE else 'numpy'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3288a9-0e57-44b8-9b62-a9427c4ace56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X010_173 = MoleculeLevels.initialize_state(\n",
    "    \"YbOH\",\n",
    "    \"173\",\n",
    "    \"X010\",\n",
    "    [1, 2],\n",
    "    M_values=\"all\",\n",
    "    I=[5 / 2, 1 / 2],\n",
    "    S=1 / 2,\n",
    "    round=8,\n",
    "    P_values=[1 / 2, 3 / 2],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5730bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X010_173 = MoleculeLevels.initialize_state(\n",
    "    \"YbOH\",\n",
    "    \"173\",\n",
    "    \"X010\",\n",
    "    [1, 2],\n",
    "    M_values=\"all\",\n",
    "    I=[5 / 2, 1 / 2],\n",
    "    S=1 / 2,\n",
    "    round=8,\n",
    "    P_values=[1 / 2, 3 / 2],\n",
    ")\n",
    "\n",
    "BASE_PARAMETERS = deepcopy(X010_173.parameters)\n",
    "FIT_PARAMETER_NAMES = [\n",
    "    \"Be\",\n",
    "    \"Gamma_SR\",\n",
    "    \"Gamma_Prime\",\n",
    "    \"bFYb\",\n",
    "    \"cYb\",\n",
    "    \"bFH\",\n",
    "    \"cH\",\n",
    "    \"e2Qq0\",\n",
    "    \"q_lD\",\n",
    "    \"p_lD\",\n",
    "    \"muE\",\n",
    "    \"g_S_eff\",\n",
    "]\n",
    "PARAM_PRIORS = {key: BASE_PARAMETERS[key] for key in FIT_PARAMETER_NAMES}\n",
    "\n",
    "\n",
    "def _default_bound(value, frac=0.2, floor=1e-6):\n",
    "    span = max(abs(value) * frac, floor)\n",
    "    return value - span, value + span\n",
    "\n",
    "\n",
    "FIT_PARAMETER_BOUNDS = {key: _default_bound(PARAM_PRIORS[key]) for key in FIT_PARAMETER_NAMES}\n",
    "\n",
    "print(f\"Loaded {X010_173.iso_state} with {len(FIT_PARAMETER_NAMES)} fit parameters tracked.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f776b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_state_parameters(state, updates=None):\n",
    "    \"\"\"Update the molecule parameters, rebuild the Hamiltonian, and refresh eigenvectors.\"\"\"\n",
    "    updates = updates or {}\n",
    "    new_params = {**BASE_PARAMETERS}\n",
    "    new_params.update(updates)\n",
    "\n",
    "    state.parameters = new_params\n",
    "    state.library.parameters[state.iso_state] = new_params\n",
    "    state.H_function, state.H_symbolic = state.library.H_builders[state.iso_state](\n",
    "        state.q_numbers,\n",
    "        state.parameters,\n",
    "        state.matrix_elements,\n",
    "        M_values=state.M_values,\n",
    "        precision=state.round,\n",
    "    )\n",
    "    state.eigensystem(0, 1e-8, order=True, method=\"torch\", set_attr=True)\n",
    "    state.generate_parities(state.evecs0)\n",
    "    return state\n",
    "\n",
    "\n",
    "def parameter_vector_to_dict(vector):\n",
    "    return {name: value for name, value in zip(FIT_PARAMETER_NAMES, vector)}\n",
    "\n",
    "\n",
    "def current_parameter_dict(state=None):\n",
    "    source = state.parameters if state is not None else BASE_PARAMETERS\n",
    "    return {name: source[name] for name in FIT_PARAMETER_NAMES}\n",
    "\n",
    "\n",
    "def parameters_to_vector(params):\n",
    "    return np.array([params[name] for name in FIT_PARAMETER_NAMES], dtype=float)\n",
    "\n",
    "\n",
    "set_state_parameters(X010_173)\n",
    "baseline_parameter_vector = parameters_to_vector(current_parameter_dict(X010_173))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8c6ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental data setup and frequency transform configuration\n",
    "EXPERIMENTAL_DATA_PATH = Path(\"/absolute/path/to/your/experimental_assignments.csv\")  # TODO: update\n",
    "REQUIRED_COLUMNS = [\"state index 0\", \"state index 1\", \"freq_obs\"]\n",
    "\n",
    "if EXPERIMENTAL_DATA_PATH.exists():\n",
    "    observed_df = pd.read_csv(EXPERIMENTAL_DATA_PATH)\n",
    "    observed_df.columns = [col.strip() for col in observed_df.columns]\n",
    "    missing = [col for col in REQUIRED_COLUMNS if col not in observed_df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns in experimental data: {missing}\")\n",
    "else:\n",
    "    observed_df = pd.DataFrame(columns=REQUIRED_COLUMNS + [\"uncertainty\"])\n",
    "    print(\"Experimental data file not found. Update EXPERIMENTAL_DATA_PATH and re-run this cell.\")\n",
    "\n",
    "if \"uncertainty\" not in observed_df.columns:\n",
    "    observed_df[\"uncertainty\"] = 1.0  # MHz weights (set to 1 if unknown)\n",
    "\n",
    "observed_df = observed_df.copy()\n",
    "for col in [\"freq_obs\", \"uncertainty\"]:\n",
    "    if col in observed_df.columns:\n",
    "        observed_df[col] = pd.to_numeric(observed_df[col], errors=\"coerce\")\n",
    "\n",
    "observed_df = observed_df.dropna(subset=[\"freq_obs\"]).reset_index(drop=True)\n",
    "\n",
    "# Frequency transform controls (matching the previous plotting convention)\n",
    "FREQ_OFFSET = (106.089 - 97.58) * 2  # MHz\n",
    "FREQ_SCALE = 0.5  # Divide by two for two-photon frequency conversion\n",
    "FREQ_SHIFT = -90.0  # Additional shift applied after scaling\n",
    "\n",
    "\n",
    "def model_frequency_transform(raw_freq):\n",
    "    \"\"\"Map raw transition frequency from the model to the experimental frequency axis.\"\"\"\n",
    "    return (raw_freq - FREQ_OFFSET) * FREQ_SCALE + FREQ_SHIFT\n",
    "\n",
    "\n",
    "TRANSITION_INDEX_SET = None  # Replace with a list of indices to restrict transitions if desired\n",
    "LASER_POLARIZATION = \"orth\"\n",
    "PARITY_SIGN = 1\n",
    "INTENSITY_THRESHOLD = None  # Set to a float to discard transitions with weaker intensity\n",
    "EZ_FIELD = 40  # Update if the experimental conditions change\n",
    "B_FIELD = 1e-8\n",
    "RUN_OPTIMIZATION = False  # Set to True to launch least-squares fitting```} வ assistant to=functions.edit_notebookища to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions.edit_notebook to=functions edit notebook tool aborted? Wait weird output? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b599a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_model_transitions(\n",
    "    state,\n",
    "    Ez=EZ_FIELD,\n",
    "    B=B_FIELD,\n",
    "    indices=None,\n",
    "    parity_sign=PARITY_SIGN,\n",
    "    polarization=LASER_POLARIZATION,\n",
    "):\n",
    "    index_list = indices if indices is not None else TRANSITION_INDEX_SET\n",
    "    if index_list is None:\n",
    "        index_list = list(range(84))\n",
    "\n",
    "    result = state.calculate_two_photon_spectrum(\n",
    "        Ez,\n",
    "        B,\n",
    "        index_list,\n",
    "        parity_sign=parity_sign,\n",
    "        laser_polarization=polarization,\n",
    "    )\n",
    "    transitions = pd.DataFrame(result[1])\n",
    "\n",
    "    if not transitions.empty:\n",
    "        transitions[\"freq_model\"] = transitions[\"freq\"].apply(model_frequency_transform)\n",
    "        if INTENSITY_THRESHOLD is not None:\n",
    "            intensity_key = next(\n",
    "                (key for key in [\"intensity\", \"Intensity\", \"strength\"] if key in transitions.columns),\n",
    "                None,\n",
    "            )\n",
    "            if intensity_key is not None:\n",
    "                transitions = transitions[transitions[intensity_key] >= INTENSITY_THRESHOLD].reset_index(drop=True)\n",
    "\n",
    "    return transitions, result\n",
    "\n",
    "\n",
    "def merge_predictions_with_experiment(predicted_df, experimental_df):\n",
    "    if experimental_df.empty:\n",
    "        predicted_df = predicted_df.copy()\n",
    "        predicted_df[\"freq_obs\"] = np.nan\n",
    "        predicted_df[\"residual\"] = np.nan\n",
    "        predicted_df[\"weight\"] = 1.0\n",
    "        return predicted_df, pd.DataFrame(), predicted_df\n",
    "\n",
    "    merge_cols = [\"state index 0\", \"state index 1\"]\n",
    "    for col in [\"M0\", \"M1\"]:\n",
    "        if col in experimental_df.columns and col in predicted_df.columns:\n",
    "            merge_cols.append(col)\n",
    "\n",
    "    merged = experimental_df.merge(predicted_df, how=\"left\", on=merge_cols, suffixes=(\"_obs\", \"_model\"))\n",
    "    missing = merged[merged[\"freq_model\"].isna()].copy()\n",
    "\n",
    "    merged[\"freq_model\"] = merged[\"freq_model\"].astype(float)\n",
    "    merged[\"residual\"] = merged[\"freq_model\"] - merged[\"freq_obs\"]\n",
    "    if \"uncertainty\" in merged.columns:\n",
    "        weights = merged[\"uncertainty\"].replace(0, np.nan).fillna(1.0)\n",
    "    else:\n",
    "        weights = pd.Series(1.0, index=merged.index)\n",
    "    merged[\"weight\"] = weights\n",
    "    merged[\"weighted_residual\"] = merged[\"residual\"] / merged[\"weight\"]\n",
    "\n",
    "    matched = merged[merged[\"freq_model\"].notna()].copy()\n",
    "    return matched, missing, predicted_df\n",
    "\n",
    "\n",
    "def summarize_fit(matched_df):\n",
    "    if matched_df.empty:\n",
    "        return {\"rms\": np.nan, \"weighted_rms\": np.nan, \"n_points\": 0}\n",
    "\n",
    "    valid = np.isfinite(matched_df[\"residual\"]) & np.isfinite(matched_df[\"weight\"])\n",
    "    if not valid.any():\n",
    "        return {\"rms\": np.nan, \"weighted_rms\": np.nan, \"n_points\": 0}\n",
    "\n",
    "    residuals = matched_df.loc[valid, \"residual\"].to_numpy()\n",
    "    weights = matched_df.loc[valid, \"weight\"].to_numpy()\n",
    "    rms = np.sqrt(np.mean(residuals**2))\n",
    "    weighted_rms = np.sqrt(np.mean((residuals / weights) ** 2))\n",
    "    return {\"rms\": rms, \"weighted_rms\": weighted_rms, \"n_points\": int(valid.sum())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d872fd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_predicted_df, baseline_raw = compute_model_transitions(X010_173)\n",
    "baseline_matched_df, baseline_missing_df, baseline_predicted_df = merge_predictions_with_experiment(\n",
    "    baseline_predicted_df, observed_df\n",
    ")\n",
    "baseline_summary = summarize_fit(baseline_matched_df)\n",
    "\n",
    "print(\"Baseline comparison summary:\", baseline_summary)\n",
    "if not baseline_missing_df.empty:\n",
    "    print(f\"Unmatched experimental assignments: {len(baseline_missing_df)}\")\n",
    "\n",
    "\n",
    "def weighted_residual_vector(param_vector):\n",
    "    updates = parameter_vector_to_dict(param_vector)\n",
    "    set_state_parameters(X010_173, updates)\n",
    "    predicted_df, _ = compute_model_transitions(X010_173)\n",
    "    matched_df, missing_df, _ = merge_predictions_with_experiment(predicted_df, observed_df)\n",
    "    if matched_df.empty:\n",
    "        raise ValueError(\n",
    "            \"No model transitions matched the experimental assignments. \"\n",
    "            \"Adjust TRANSITION_INDEX_SET or check the assignments.\"\n",
    "        )\n",
    "    return matched_df[\"weighted_residual\"].to_numpy()\n",
    "\n",
    "\n",
    "optimization_result = None\n",
    "fit_parameters = parameter_vector_to_dict(baseline_parameter_vector)\n",
    "fit_predicted_df = baseline_predicted_df\n",
    "fit_matched_df = baseline_matched_df\n",
    "fit_missing_df = baseline_missing_df\n",
    "fit_summary = baseline_summary\n",
    "\n",
    "if RUN_OPTIMIZATION and not observed_df.empty:\n",
    "    lower_bounds = np.array([FIT_PARAMETER_BOUNDS[name][0] for name in FIT_PARAMETER_NAMES])\n",
    "    upper_bounds = np.array([FIT_PARAMETER_BOUNDS[name][1] for name in FIT_PARAMETER_NAMES])\n",
    "\n",
    "    optimization_result = least_squares(\n",
    "        weighted_residual_vector,\n",
    "        x0=baseline_parameter_vector,\n",
    "        bounds=(lower_bounds, upper_bounds),\n",
    "        verbose=2,\n",
    "    )\n",
    "    fit_parameters = parameter_vector_to_dict(optimization_result.x)\n",
    "    set_state_parameters(X010_173, fit_parameters)\n",
    "    fit_predicted_df, _ = compute_model_transitions(X010_173)\n",
    "    fit_matched_df, fit_missing_df, fit_predicted_df = merge_predictions_with_experiment(\n",
    "        fit_predicted_df, observed_df\n",
    "    )\n",
    "    fit_summary = summarize_fit(fit_matched_df)\n",
    "    print(\"Fit summary:\", fit_summary)\n",
    "\n",
    "fit_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e705e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not fit_matched_df.empty:\n",
    "    display(fit_matched_df[[\"state index 0\", \"state index 1\", \"freq_obs\", \"freq_model\", \"residual\"]].head())\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.errorbar(\n",
    "        fit_matched_df[\"freq_obs\"],\n",
    "        fit_matched_df[\"freq_model\"],\n",
    "        yerr=fit_matched_df.get(\"uncertainty\", pd.Series(0, index=fit_matched_df.index)),\n",
    "        fmt=\"o\",\n",
    "        ms=6,\n",
    "        alpha=0.7,\n",
    "        label=\"Matched transitions\",\n",
    "    )\n",
    "    lims = [\n",
    "        min(fit_matched_df[\"freq_obs\"].min(), fit_matched_df[\"freq_model\"].min()) - 0.1,\n",
    "        max(fit_matched_df[\"freq_obs\"].max(), fit_matched_df[\"freq_model\"].max()) + 0.1,\n",
    "    ]\n",
    "    ax.plot(lims, lims, \"k--\", label=\"Perfect agreement\")\n",
    "    ax.set_xlim(lims)\n",
    "    ax.set_ylim(lims)\n",
    "    ax.set_xlabel(\"Observed frequency (MHz)\")\n",
    "    ax.set_ylabel(\"Model frequency (MHz)\")\n",
    "    ax.set_title(\"Observed vs. model transition frequencies\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No matched transitions to visualize yet. Load experimental data and rerun the fit.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b685cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unassigned frequency data configuration\n",
    "UNASSIGNED_DATA_PATH = Path(\"/absolute/path/to/your/unassigned_frequencies.csv\")  # TODO: update\n",
    "UNASSIGNED_FREQ_COLUMN = \"freq_obs\"  # Column name in the CSV file\n",
    "UNASSIGNED_WEIGHT_COLUMN = None  # Set to column name if relative intensities are available\n",
    "UNASSIGNED_SIGMA = 0.03  # MHz Gaussian width used to broaden stick spectra\n",
    "\n",
    "if UNASSIGNED_DATA_PATH.exists():\n",
    "    unassigned_df = pd.read_csv(UNASSIGNED_DATA_PATH)\n",
    "    if UNASSIGNED_FREQ_COLUMN not in unassigned_df.columns:\n",
    "        raise ValueError(\n",
    "            f\"Column '{UNASSIGNED_FREQ_COLUMN}' not found in unassigned data: {unassigned_df.columns.tolist()}\"\n",
    "        )\n",
    "    observed_unassigned_freqs = pd.to_numeric(\n",
    "        unassigned_df[UNASSIGNED_FREQ_COLUMN], errors=\"coerce\"\n",
    "    ).dropna().to_numpy()\n",
    "    if UNASSIGNED_WEIGHT_COLUMN and UNASSIGNED_WEIGHT_COLUMN in unassigned_df.columns:\n",
    "        observed_unassigned_weights = pd.to_numeric(\n",
    "            unassigned_df[UNASSIGNED_WEIGHT_COLUMN], errors=\"coerce\"\n",
    "        ).fillna(1.0).to_numpy()\n",
    "    else:\n",
    "        observed_unassigned_weights = np.ones_like(observed_unassigned_freqs)\n",
    "    print(f\"Loaded {len(observed_unassigned_freqs)} unassigned transition frequencies.\")\n",
    "else:\n",
    "    observed_unassigned_freqs = np.array([])\n",
    "    observed_unassigned_weights = np.array([])\n",
    "    print(\"Unassigned frequency data not found. Update UNASSIGNED_DATA_PATH and re-run.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd6b93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_broadened_spectrum(frequencies, weights=None, freq_axis=None, sigma=UNASSIGNED_SIGMA):\n",
    "    if freq_axis is None:\n",
    "        if frequencies.size == 0:\n",
    "            return np.linspace(0, 1, 1000), np.zeros(1000)\n",
    "        f_min, f_max = frequencies.min() - 3 * sigma, frequencies.max() + 3 * sigma\n",
    "        freq_axis = np.linspace(f_min, f_max, 2000)\n",
    "    if weights is None:\n",
    "        weights = np.ones_like(frequencies)\n",
    "    if frequencies.size == 0:\n",
    "        return freq_axis, np.zeros_like(freq_axis)\n",
    "    diff = freq_axis[:, None] - frequencies[None, :]\n",
    "    spectrum = np.exp(-(diff**2) / (2 * sigma**2)) @ weights\n",
    "    return freq_axis, spectrum\n",
    "\n",
    "\n",
    "def spectral_residual(predicted_freqs, observed_freqs, predicted_weights=None, observed_weights=None, sigma=UNASSIGNED_SIGMA):\n",
    "    if observed_freqs.size == 0 or predicted_freqs.size == 0:\n",
    "        return np.inf\n",
    "    freq_axis, observed_spec = gaussian_broadened_spectrum(observed_freqs, observed_weights, sigma=sigma)\n",
    "    _, predicted_spec = gaussian_broadened_spectrum(predicted_freqs, predicted_weights, freq_axis=freq_axis, sigma=sigma)\n",
    "    observed_spec /= observed_spec.max() if observed_spec.max() else 1\n",
    "    predicted_spec /= predicted_spec.max() if predicted_spec.max() else 1\n",
    "    return np.sqrt(np.mean((predicted_spec - observed_spec) ** 2))\n",
    "\n",
    "\n",
    "def transition_frequency_set(state, Ez=EZ_FIELD, B=B_FIELD, indices=None, **kwargs):\n",
    "    transitions, raw = compute_model_transitions(state, Ez=Ez, B=B, indices=indices, **kwargs)\n",
    "    if transitions.empty:\n",
    "        return np.array([]), np.array([]), raw\n",
    "    weights = None\n",
    "    for candidate in [\"intensity\", \"Intensity\", \"strength\", \"Strength\"]:\n",
    "        if candidate in transitions.columns:\n",
    "            weights = transitions[candidate].to_numpy()\n",
    "            break\n",
    "    return transitions[\"freq_model\"].to_numpy(), weights, raw\n",
    "\n",
    "\n",
    "def unassigned_spectrum_loss(state, Ez=EZ_FIELD, B=B_FIELD, sigma=UNASSIGNED_SIGMA, observed_freqs=None, observed_weights=None, **kwargs):\n",
    "    if observed_freqs is None:\n",
    "        observed_freqs = observed_unassigned_freqs\n",
    "    if observed_weights is None:\n",
    "        observed_weights = observed_unassigned_weights\n",
    "    predicted_freqs, predicted_weights, _ = transition_frequency_set(state, Ez=Ez, B=B, **kwargs)\n",
    "    return spectral_residual(predicted_freqs, observed_freqs, predicted_weights, observed_weights, sigma=sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0748d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter space exploration for unassigned spectra\n",
    "UNASSIGNED_PARAMETER_NAMES = FIT_PARAMETER_NAMES  # Override to restrict search\n",
    "UNASSIGNED_PARAMETER_BOUNDS = {name: FIT_PARAMETER_BOUNDS[name] for name in UNASSIGNED_PARAMETER_NAMES}\n",
    "UNASSIGNED_RANDOM_SAMPLES = 100\n",
    "UNASSIGNED_TOP_K = 10\n",
    "USE_GAUSSIAN_PROCESS = True  # Toggle Bayesian surrogate refinement\n",
    "\n",
    "\n",
    "def sample_parameter_vector(bounds_dict):\n",
    "    return np.array([\n",
    "        np.random.uniform(low=low, high=high) for (low, high) in bounds_dict.values()\n",
    "    ])\n",
    "\n",
    "\n",
    "def evaluate_parameter_vector(param_vector, state=None, observed_freqs=None, observed_weights=None):\n",
    "    state = state or X010_173\n",
    "    updates = parameter_vector_to_dict(param_vector)\n",
    "    set_state_parameters(state, updates)\n",
    "    loss = unassigned_spectrum_loss(\n",
    "        state,\n",
    "        observed_freqs=observed_freqs,\n",
    "        observed_weights=observed_weights,\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def random_explore_unassigned(state, n_samples=UNASSIGNED_RANDOM_SAMPLES, bounds=None, observed_freqs=None, observed_weights=None):\n",
    "    bounds = bounds or UNASSIGNED_PARAMETER_BOUNDS\n",
    "    names = list(bounds.keys())\n",
    "    samples = []\n",
    "    for _ in range(n_samples):\n",
    "        vec = sample_parameter_vector(bounds)\n",
    "        loss = evaluate_parameter_vector(vec, state=state, observed_freqs=observed_freqs, observed_weights=observed_weights)\n",
    "        samples.append({\"params\": parameter_vector_to_dict(vec), \"vector\": vec, \"loss\": loss})\n",
    "    samples.sort(key=lambda x: x[\"loss\"])\n",
    "    return names, samples\n",
    "\n",
    "\n",
    "random_search_results = None\n",
    "if observed_unassigned_freqs.size:\n",
    "    names, random_search_results = random_explore_unassigned(\n",
    "        X010_173,\n",
    "        n_samples=UNASSIGNED_RANDOM_SAMPLES,\n",
    "        bounds=UNASSIGNED_PARAMETER_BOUNDS,\n",
    "        observed_freqs=observed_unassigned_freqs,\n",
    "        observed_weights=observed_unassigned_weights,\n",
    "    )\n",
    "    best_candidates = random_search_results[:UNASSIGNED_TOP_K]\n",
    "    print(\"Top random-search candidates (loss is spectrum RMSE):\")\n",
    "    for idx, candidate in enumerate(best_candidates, 1):\n",
    "        print(f\"#{idx}: loss={candidate['loss']:.5f}\")\n",
    "else:\n",
    "    print(\"No unassigned data loaded; skipping random exploration.\")\n",
    "\n",
    "\n",
    "surrogate_model = None\n",
    "surrogate_history = []\n",
    "\n",
    "if USE_GAUSSIAN_PROCESS and observed_unassigned_freqs.size and random_search_results:\n",
    "    try:\n",
    "        from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "        from sklearn.gaussian_process.kernels import Matern, WhiteKernel\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "        kernel = Matern(length_scale=np.ones(len(names)), nu=2.5) + WhiteKernel(noise_level=1e-6)\n",
    "        gp = GaussianProcessRegressor(kernel=kernel, normalize_y=True, n_restarts_optimizer=3)\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        X_samples = np.array([entry[\"vector\"] for entry in random_search_results])\n",
    "        y_samples = np.array([entry[\"loss\"] for entry in random_search_results])\n",
    "        scaler.fit(X_samples)\n",
    "        gp.fit(scaler.transform(X_samples), y_samples)\n",
    "\n",
    "        surrogate_model = {\"gp\": gp, \"scaler\": scaler, \"names\": names}\n",
    "\n",
    "        def propose_next(gp_model, n_candidates=512):\n",
    "            raw = np.array([sample_parameter_vector(UNASSIGNED_PARAMETER_BOUNDS) for _ in range(n_candidates)])\n",
    "            mu, sigma = gp_model[\"gp\"].predict(gp_model[\"scaler\"].transform(raw), return_std=True)\n",
    "            acquisition = mu - 1.96 * sigma  # Lower Confidence Bound\n",
    "            best_idx = np.argmin(acquisition)\n",
    "            return raw[best_idx], acquisition[best_idx]\n",
    "\n",
    "        for iteration in range(10):\n",
    "            candidate_vec, acquisition_value = propose_next(surrogate_model)\n",
    "            candidate_loss = evaluate_parameter_vector(\n",
    "                candidate_vec,\n",
    "                state=X010_173,\n",
    "                observed_freqs=observed_unassigned_freqs,\n",
    "                observed_weights=observed_unassigned_weights,\n",
    "            )\n",
    "            surrogate_history.append({\n",
    "                \"vector\": candidate_vec,\n",
    "                \"params\": parameter_vector_to_dict(candidate_vec),\n",
    "                \"loss\": candidate_loss,\n",
    "                \"acquisition\": acquisition_value,\n",
    "            })\n",
    "            # Update GP with new observation\n",
    "            X_samples = np.vstack([X_samples, candidate_vec])\n",
    "            y_samples = np.append(y_samples, candidate_loss)\n",
    "            scaler.fit(X_samples)\n",
    "            gp.fit(scaler.transform(X_samples), y_samples)\n",
    "\n",
    "        print(f\"Gaussian-process refinement completed with {len(surrogate_history)} additional evaluations.\")\n",
    "    except ImportError:\n",
    "        print(\"scikit-learn not available; skipping Gaussian-process refinement.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c469b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_candidate_table(random_results=None, surrogate_results=None, top_k=UNASSIGNED_TOP_K):\n",
    "    records = []\n",
    "    for source, entries in [(\"random\", random_results or []), (\"gp\", surrogate_results or [])]:\n",
    "        for entry in (entries if isinstance(entries, list) else []):\n",
    "            row = {\"source\": source, \"loss\": entry[\"loss\"], **entry.get(\"params\", {})}\n",
    "            records.append(row)\n",
    "    if not records:\n",
    "        return pd.DataFrame()\n",
    "    df = pd.DataFrame(records)\n",
    "    df = df.sort_values(\"loss\").head(top_k).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "candidate_table = collect_candidate_table(\n",
    "    random_results=random_search_results,\n",
    "    surrogate_results=surrogate_history,\n",
    ")\n",
    "\n",
    "if not candidate_table.empty:\n",
    "    display(candidate_table)\n",
    "else:\n",
    "    print(\"No parameter candidates generated yet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed1dd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrum_comparison(candidate_params, observed_freqs=None, observed_weights=None, sigma=UNASSIGNED_SIGMA, title_suffix=\"\"):\n",
    "    observed_freqs = observed_freqs if observed_freqs is not None else observed_unassigned_freqs\n",
    "    observed_weights = observed_weights if observed_weights is not None else observed_unassigned_weights\n",
    "    if observed_freqs.size == 0:\n",
    "        print(\"No unassigned frequencies to visualize.\")\n",
    "        return\n",
    "    set_state_parameters(X010_173, candidate_params)\n",
    "    predicted_freqs, predicted_weights, _ = transition_frequency_set(X010_173)\n",
    "    freq_axis, observed_spec = gaussian_broadened_spectrum(observed_freqs, observed_weights, sigma=sigma)\n",
    "    _, predicted_spec = gaussian_broadened_spectrum(predicted_freqs, predicted_weights, freq_axis=freq_axis, sigma=sigma)\n",
    "    observed_spec /= observed_spec.max() if observed_spec.max() else 1\n",
    "    predicted_spec /= predicted_spec.max() if predicted_spec.max() else 1\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(freq_axis, observed_spec, label=\"Observed\", lw=2)\n",
    "    plt.plot(freq_axis, predicted_spec, label=\"Predicted\", lw=2)\n",
    "    plt.xlabel(\"Frequency (MHz)\")\n",
    "    plt.ylabel(\"Normalized intensity\")\n",
    "    plt.title(f\"Spectrum overlay {title_suffix}\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if candidate_table.shape[0]:\n",
    "    best_candidate_params = candidate_table.iloc[0].drop(labels=[\"source\", \"loss\"]).to_dict()\n",
    "    print(\"Plotting spectrum overlay for top candidate...\")\n",
    "    plot_spectrum_comparison(best_candidate_params, title_suffix=f\"loss={candidate_table.iloc[0]['loss']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
